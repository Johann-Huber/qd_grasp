# Created by Giuseppe Paolo 
# Date: 18/12/2020

from cmaes import CMA
from external_pkg.serene.core.evolvers import MAPElites
from external_pkg.serene.core.population.archive import Grid
from external_pkg.serene.core.population.population import Population
from external_pkg.serene.environments.environments import registered_envs
import numpy as np

class OptimizingEmitter(object):
  """
  This class is a wrapper for the CMA-ES algorithm
  """
  def __init__(self, init_mean, id, mutation_rate, bounds, parameters):
    self.init_mean = init_mean
    self.id = id
    self._mutation_rate = mutation_rate
    self.steps = 0
    self._params = parameters
    self._bounds = bounds
    self.stored = 0

    # List of lists. Each inner list corresponds to the values obtained during a step
    # We init with the ancestor reward so it's easier to calculate the improvement
    self.values = []
    self.archived_values = []

    self._cmaes = CMA(mean=self.init_mean.copy(),
                      sigma=self._mutation_rate,
                      bounds=self._bounds,
                      seed=self._params.seed,
                      population_size=self._params.emitter_population)

  def ask(self):
    return self._cmaes.ask()

  def tell(self, solutions):
    return self._cmaes.tell(solutions)

  def should_stop(self):
    """
    Checks internal stopping criteria
    :return:
    """
    return self._cmaes.should_stop()



class CMAME(MAPElites):
  """
  Implements the CMA-ME algorithm from https://arxiv.org/pdf/1912.02400.pdf.
  Given that we use CMA-ES emitters, the implementation is the one of OPTIMIZING EMITTER
  It does not handle the emitters as my algorithm, so it heredits from the BaseEvolver, not the EmitterEvolver
  """
  def __init__(self, parameters):
    super().__init__(parameters)
    self.emitter_based = False
    self.emitter_idx = None
    self.emitters_pop = []
    # Instantiated only to extract genome size
    controller = registered_envs[self.params.env_name]['controller']['controller'](**registered_envs[self.params.env_name]['controller'])
    self.genome_size = controller.genome_size
    self.bounds = self.params.genome_limit * np.ones((self.genome_size, len(self.params.genome_limit)))

  def generate_offspring(self, parents, generation, pool=None):
    """
    The offsprings are the ones generated by the selected emitter
    :param parents:
    :param generation:
    :param pool:
    :return:
    """
    # Do this only the first time, when the first N agents are generated
    if self.initial_pop:
      self.initial_pop = False
      # We do not store the agents of the initial pop in the archive. Just use them to init the emitters
      # Init emitter population with all agents in the initial population.
      for agent in parents:
        self.emitters_pop.append(OptimizingEmitter(agent['genome'], agent['id'], 0.5, self.bounds, self.params))

    # Now select emitter to use
    self.emitter_idx = np.argmin([em.stored for em in self.emitters_pop]) # Select emitter that generated the least solutions

    offsprings = Population(self.params, init_size=0, name='offsprings')
    for i in range(self.params.emitter_population): # The batch is the pop size
      off = self.agent_template.copy() # Get new agent
      off['genome'] = self.emitters_pop[self.emitter_idx].ask()
      off['parent'] = self.emitters_pop[self.emitter_idx].id
      off['ancestor'] = self.emitters_pop[self.emitter_idx].id
      offsprings.add(off)

    offs_ids = parents.agent_id + np.array(range(len(offsprings)))  # Calculate offs IDs
    offsprings['id'] = offs_ids  # Update offs IDs
    offsprings['born'] = [generation] * offsprings.size
    parents.agent_id = max(offs_ids) + 1  # This saves the maximum ID reached till now
    return offsprings

  def update_archive(self, population, offsprings, generation):
    """
    Here we use the offprings to update the emitter distribution and the archive grid
    :param population:
    :param offsprings:
    :param generation:
    :return:
    """
    # Store agents
    did_store = False
    for agent in offsprings:
      agent['stored'] = generation
      if self.archive.store(agent):
        self.emitters_pop[self.emitter_idx].stored += 1
        did_store = True

    if did_store:
      # Update emitter distribution (This one needs to be changed if wanting to use improvement emitters)
      solutions = [(genome, -value) for genome, value in zip(offsprings['genome'], offsprings['reward'])]
      self.emitters_pop[self.emitter_idx].tell(solutions)
    else:
      # If the emitter did not store anything, we restart it from another elite
      elite_idx = np.random.choice(self.archive.size)
      self.emitters_pop[self.emitter_idx] = OptimizingEmitter(self.archive['genome'][elite_idx],
                                                          self.archive['id'][elite_idx],
                                                          mutation_rate=0.5,
                                                          bounds=self.bounds,
                                                          parameters=self.params)